{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93c649-85d1-4bf5-956e-451e2287026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run path/to/utils.py.ipynb (in this case, I had the utils.py.ipynb notebook in the same folder as the other notebooks)\n",
    "# Running this will also let you know the version of tenserflow \"TF\" \n",
    "# In my case, I built the TF 2.10.0 version from source for the Windows environment --> latest tenserflow version that supports training models on a gpu in Windows\n",
    "# Please be aware that you may need to pick the numpy and pandas versions carefully to avoid issues with running this notebook (numpy version = pandas version = ) \n",
    "    ## For more details please visit the tensorflow website (build from source - windows): https://www.tensorflow.org/install/source_windows\n",
    "%run utils.py.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4feac52-1ba0-428a-883e-15dfbddd2f08",
   "metadata": {},
   "source": [
    "# Many-to-Many (Sequence-to-Sequence) Bi-LSTM Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933dadf-cc73-451d-86d1-d28d6f467065",
   "metadata": {},
   "source": [
    "## Contents: \n",
    "- Dataset Creation\n",
    "- Training Model\n",
    "- Saving Model\n",
    "- Displaying Results\n",
    "- Saving Results\n",
    "- Loading Model\n",
    "- Evaluating Model\n",
    "- Additional Examples: (Many-to-One) + LSTM, GRU, Bi-GRU, ANN, Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654d8c6-b70f-402f-a959-1f886bb49b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter path of the excel file\n",
    "Production_data_path = 'Example_Data.xlsx'\n",
    "excelfile = pd.ExcelFile(Production_data_path)\n",
    "# Find all sheet names of the excel file in given path\n",
    "all_sheets = pd.ExcelFile(Production_data_path).sheet_names\n",
    "\n",
    "# Allow user to select multiple sheet names from a single Excel file in a GUI \n",
    "# RETURN VARILABLE NAME: \"user_selected_sheets\" --> set as a global variable inside \"select_sheets\" function\n",
    "user_selected_sheets = select_sheets(sheet_names = all_sheets)\n",
    "# from my_methods import user_selected_sheets # importing the global variable after setting it up using the GUI (user_selected_sheets is a global variable that is created after executing the GUI)\n",
    "\n",
    "# Define an empty list to store individual DataFrames\n",
    "list_of_dfs = []\n",
    "\n",
    "for sheet in user_selected_sheets:\n",
    "    \n",
    "    # Parse data from each worksheet as a Pandas DataFrame\n",
    "    df = excelfile.parse(sheet)\n",
    "\n",
    "    # And append it to the list\n",
    "    list_of_dfs.append(df)\n",
    "    \n",
    "# Combine all DataFrames into one\n",
    "Production_data = pd.concat(list_of_dfs, keys=user_selected_sheets, names=['Sheet_names',None]).reset_index(level=0).reset_index(drop=True)\n",
    "\n",
    "# Print - High level info on production data\n",
    "print('\\nCountries:')\n",
    "print(['United States']) # can be extracted from Production_data later\n",
    "print('\\nStates:')\n",
    "print(['North Dakota']) # can be extracted from Production_data later\n",
    "print('\\nCounties:')\n",
    "print(list(Production_data['County'].unique()))\n",
    "print('\\nReservoirs:')\n",
    "print(list(Production_data['targetFormation'].unique()))\n",
    "print('\\nNumber of selected wells:')\n",
    "print(len(Production_data['API/UWI List'].unique()))\n",
    "\n",
    "# Print - Low level info on production data\n",
    "print('\\nFirst Production Years Interval:')\n",
    "print (Production_data['firstProdDate'].min().year,'-',Production_data['firstProdDate'].max().year)\n",
    "print('\\nTrue Vertical Depth (TVD) variation')\n",
    "print (Production_data['TVD'].min(),'-',Production_data['TVD'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbca9f1-50f7-4d6c-8896-94b188cf58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data based on train, val, test percentages and remaining window size for val and test sets\n",
    "train_percent = 0.6\n",
    "val_percent = 0.2\n",
    "test_percent = 0.2\n",
    "label_columns = ['Monthly Oil','Monthly Gas','Monthly Water']\n",
    "control_parameters = ['Days']\n",
    "\n",
    "Processed_Production_data = process_data(Production_data = Production_data, train_percent = train_percent, val_percent = val_percent, test_percent = test_percent, label_columns = label_columns, control_parameters = control_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582d281-4351-4393-9b8c-aa51e916ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Processed Production Data\n",
    "display(Processed_Production_data)\n",
    "\n",
    "# Add First production date's month and year as part of the static variables to include in the model\n",
    "Processed_Production_data['First_Prod_Month'] = Processed_Production_data['firstProdDate'].dt.month\n",
    "Processed_Production_data['First_Prod_Year'] = Processed_Production_data['firstProdDate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c0492-9547-40fc-9d09-6787f5829e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "train_df, val_df, test_df = split_data(Processed_Production_data,train_percent=0.6,val_percent=0.2,test_percent=0.2)\n",
    "\n",
    "# Count Production length of each well\n",
    "train_df['frequency'] = train_df.groupby('API/UWI List')['API/UWI List'].transform('count')\n",
    "val_df['frequency'] = val_df.groupby('API/UWI List')['API/UWI List'].transform('count')\n",
    "test_df['frequency'] = test_df.groupby('API/UWI List')['API/UWI List'].transform('count')\n",
    "\n",
    "max_train_prod_period = train_df['frequency'].unique().max()\n",
    "max_val_prod_period = val_df['frequency'].unique().max()\n",
    "max_test_prod_period = test_df['frequency'].unique().max()\n",
    "min_train_prod_period = train_df['frequency'].unique().min()\n",
    "min_val_prod_period = val_df['frequency'].unique().min()\n",
    "min_test_prod_period = test_df['frequency'].unique().min()\n",
    "\n",
    "# Observe maximum and minimum length of production period for each well in training data\n",
    "# Use this info to decide on train_percent, val_percent, test_percent for splitting the data\n",
    "# Use this info to decide on the maximum window size for training and testing\n",
    "print('Training Data Max Production Period:')\n",
    "print(max_train_prod_period)\n",
    "print('Validation Data Max Production Period:')\n",
    "print(max_val_prod_period)\n",
    "print('Test Data Max Production Period:')\n",
    "print(max_test_prod_period)\n",
    "print('Training Data Min Production Period:')\n",
    "print(min_train_prod_period)\n",
    "print('Validation Data Min Production Period:')\n",
    "print(min_val_prod_period)\n",
    "print('Test Data Min Production Period:')\n",
    "print(min_test_prod_period)\n",
    "\n",
    "# Create Frequency plots for production periods in Training, Validation, and Test data\n",
    "# Additionally use this plot to adjust train_percent, val_percent, test_percent for splitting the data\n",
    "print('Time Series Length of Each Well (Train,Val,Test):')\n",
    "fig, ax = plt.subplots(nrows=3, ncols=1)\n",
    "train_df['API/UWI List'].value_counts().plot(ax=ax[0], kind='bar', xlabel='Unique Wells', ylabel='Frequency', xticks = [], figsize = (15,15), title = 'Training - Time Series Length Distribution')\n",
    "val_df['API/UWI List'].value_counts().plot(ax=ax[1], kind='bar', xlabel='Unique Wells', ylabel='Frequency', xticks = [], figsize = (15,15), title = 'Validation - Time Series Length Distribution')\n",
    "test_df['API/UWI List'].value_counts().plot(ax=ax[2], kind='bar', xlabel='Unique Wells', ylabel='Frequency', xticks = [], figsize = (15,15), title = 'Test - Time Series Length Distribution')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observe the training, validation, and test data\n",
    "# Use this to confirm the data integrity before starting training and testing\n",
    "print('\\nTraining Data:')\n",
    "display(train_df)\n",
    "print('Validation Data:')\n",
    "display(val_df)\n",
    "print('Test Data:')\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804fdefc-7147-413e-93dc-43356bbff327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "train_df, val_df, test_df, train_max, train_min = normalize_data(train_df, val_df, test_df, plot_cols = ['Monthly Oil', 'Monthly Gas', 'Monthly Water', 'Days'], norm_method = 'min-max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd11b5-91c4-48d8-b913-05f12052998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['API/UWI List'] == 3306101267,'Monthly Water_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71a68b-5e40-48f5-aa15-ab0e414cc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the dynamic variables to include in the model\n",
    "dynamic_variables = ['Monthly Oil', 'Monthly Gas', 'Monthly Water', 'Days']\n",
    "\n",
    "print('\\nDynamic_variables:\\n')\n",
    "print(dynamic_variables)\n",
    "print('\\nDynamic_variables length:')\n",
    "print(len(dynamic_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7812c7-218e-4a51-af40-0ac9d184211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input required columns for training\n",
    "append_str = '_norm'\n",
    "input_columns = [sub + append_str for sub in dynamic_variables]\n",
    "labels = ['Monthly Oil', 'Monthly Gas', 'Monthly Water'] # change if necessary\n",
    "label_columns = [sub + append_str for sub in labels]\n",
    "\n",
    "print('\\nDynamic variables to use in the model:\\n')\n",
    "print(input_columns)\n",
    "print('\\nTarget variables to be predicted @ t = t+1:\\n')\n",
    "print(label_columns)\n",
    "print('\\nControl parameters for prediction of labels:\\n')\n",
    "print(list(set(input_columns) - set(label_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3842ba2-9e67-4e28-b8fd-6a913a65ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Batches for training, validation, and testing (can control many-to-many vs many-to-one + one step ahead predictions vs multi-step ahead predictions)\n",
    "\n",
    "''' input_width = label_width and shift = 1 and final rnn layer return_sequences = True --> many-to-many with one step ahead predictions'''\n",
    "''' input_width != label_width, label_width = 1 and shift = 1 and final rnn layer return_sequences = False --> many-to-one with one step ahead predictions'''\n",
    "input_width = 6\n",
    "label_width = 6 # many-to-many (sequence-to-sequence)\n",
    "label_width_one = 1 # many-to-one\n",
    "batch_number = 512 # determines how many batches to process at once. Ideally, the higher the number of batches, the smoother the gradient surface becomes.\n",
    "shift = 1 # the shift parameter determines how many steps the window will move when creating the datasets for training, validaton, and testing ( when shift=1, it means that the movement is one-by-one --> for example: a windows size of 6 will cover 1-to-6 points in the inputs and move as 2-to-7 points in the labels (outputs) for forecasting. This window will move one step ahead for the next example as 2-to-7 points for the input and 3-to-8 points for the label (output), etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b1aa9-6d3f-484f-81bd-af26c196c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Batches for training, validation, and testing\n",
    "\n",
    "# Generate window based Batches (train, val, test) --> for standard RNN (many-to-many)\n",
    "w2 = WindowGenerator(input_width = input_width, label_width = label_width, shift = shift, input_columns = input_columns, label_columns = label_columns, shuffle_data = False, batch_number = batch_number, train_df=train_df, val_df=val_df, test_df=test_df) \n",
    "\n",
    "# Generate window based Batches (train, val, test) --> for standard RNN (many-to-one) --> This is not trained in this script but, the explanation is given below.\n",
    "# w2_one = WindowGenerator(input_width = input_width, label_width = label_width_one, shift = shift, input_columns = input_columns, label_columns = label_columns, shuffle_data = False, batch_number = batch_number, train_df=train_df, val_df=val_df, test_df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfba3b2-d67c-4175-8380-2e7bb4677012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data for training (faster training times during bayesian optimization with tensor datasets)\n",
    "\n",
    "# Standard RNN (many-to-many)\n",
    "w2_train = w2.train\n",
    "w2_val = w2.val\n",
    "w2_test = w2.test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92713807-8be3-4168-ad3c-9f99e477f43e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# An example method for observing the processed training, validation, and test sets (in this case, the test set was observed but, can observe training, and validaton as well if desired)\n",
    "# Warning: Uncomment to run and display the dataset, but, be aware, can be very slow for moderately large datasets! Suggested to try with a smaller data set to see if the training, validation, and test sets is created correctly.\n",
    "# list(w2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba1e24-1004-4166-8134-234393666d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters (same for all the models)\n",
    "\n",
    "# input shape\n",
    "i = Input(shape=[input_width, len(dynamic_variables)], name='input_0') # shape(input width, dynamic features)\n",
    "\n",
    "# Validation patience for early stopping (choose this value carefully as it can impact the model performance significantly).\n",
    "patience = 30\n",
    "\n",
    "# Callback methods\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, min_lr=0.00001) # reduces learning rate during training to learn more accurately\n",
    "\n",
    "# Callback settings (restores best weights) --> This is early stopping that restores the best weights if the training somehow goes way beyond the optimum point.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  restore_best_weights=True,\n",
    "                                                  patience=patience,\n",
    "                                                  min_delta = 1e-07,\n",
    "                                                  mode='min')\n",
    "\n",
    "# Optimizer settings (Used ADAM in this case but, can choose a different optimizer for testing purposes).\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001,\n",
    "                                     beta_1=0.95,\n",
    "                                     beta_2=0.999,\n",
    "                                     epsilon=1e-07,\n",
    "                                     amsgrad=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6278c-0005-495e-9ba3-103bc28df5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewer Revision - Adding Bi-LSTM\n",
    "Standard_best_Bi_LSTM = create_model(final_layer_return_seq = True, loss = 'mse', metrics = ['mae','mape'], layers = 2, dropout_final_layer = False, dropout_value = 0.07490910432625673, units = [[244,250],[132,245]], Bi_directional = True, recurrent_dropout = 'zeros', model_type = 'LSTM', i = i, optimizer = optimizer) # ST_Hybrid = False, , c = c \n",
    "Standard_best_Bi_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad0579-b835-4726-9b06-8f68d340f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_standard_best_Bi_LSTM = Standard_best_Bi_LSTM.fit(w2_train, epochs=10, validation_data=w2_val, verbose=2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb042e2e-37ec-4e85-bf13-b9e32a31c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "Standard_best_Bi_LSTM.evaluate(w2_train)\n",
    "Standard_best_Bi_LSTM.evaluate(w2_val)\n",
    "Standard_best_Bi_LSTM.evaluate(w2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640090c-b628-4afa-8923-586c9986c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves a plot of oil, gas, and water phases for each well\n",
    "# Creates a \"Plots\" folder where this script is located (if it does not already exist)\n",
    "# Can select either all wells to evaluate (index_slice_start = 0 and index = \"all\") or the \"ith\" well-ot-\"nth\" well (index_slice_start = i and index = n).\n",
    "# index_slice_start = i (i represents the index of the well to start the evaluation) i = 0 means the first well and i = 5 means the 6th well.\n",
    "\n",
    "\n",
    "# Get the directory where the script is running\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# Prepare to save to the \"Plots\" folder\n",
    "folder_name = \"Plots\"\n",
    "plots_folder_path = os.path.join(script_dir, folder_name)\n",
    "\n",
    "# Create the \"Plots\" folder if it does not already exist\n",
    "os.makedirs(plots_folder_path, exist_ok=True)\n",
    "\n",
    "print(f\"Folder created at: {plots_folder_path}\")\n",
    "\n",
    "saved_data  = save_pred_results(input_width = 6,\n",
    "                               label_width = 6,\n",
    "                               norm_method = 'min-max',\n",
    "                               input_columns = input_columns,\n",
    "                               label_columns = label_columns,\n",
    "                               batch_number = 512,\n",
    "                               index_slice_start = 0, # Chooses which well to begin the evaluation with (0 = first well)\n",
    "                               path_to_save_pred_plots = plots_folder_path, \n",
    "                               model = Standard_best_Bi_LSTM,\n",
    "                               model_name = 'Bi_LSTM_monthly_rates_min_max_sigmoid',\n",
    "                               index_slice = 5, # Can choose \"all\" for evaluating the model on all the wells (Warning: slower if there are a lot of wells to evaluate)\n",
    "                               train_df = train_df, \n",
    "                               val_df = val_df, \n",
    "                               test_df = test_df, \n",
    "                               train_mu = train_min, \n",
    "                               train_sigma = train_max,\n",
    "                               logscale = 'off',\n",
    "                               normscale = 'off',\n",
    "                               plot_loss = 'mae',\n",
    "                               split_loss = 'off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048aaee-ac01-4da7-9331-04366271788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example for saving the training history into a json file to load later using the \"load_model()\" function\n",
    "# Creates the Model_histories\" folder to save the training history (if it doesn't already exist)\n",
    "\n",
    "# Get the directory where the script is running\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# Prepare to save to the \"Model_histories\" folder\n",
    "folder_name = \"Model_histories\"\n",
    "histories_folder_path = os.path.join(script_dir, folder_name)\n",
    "\n",
    "# Create the \"Model_Histories\" folder if it does not already exist\n",
    "os.makedirs(histories_folder_path, exist_ok=True)\n",
    "\n",
    "print(f\"Folder created at: {histories_folder_path}\")\n",
    "\n",
    "history_path = histories_folder_path\n",
    "\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = history_standard_best_Bi_LSTM.history\n",
    "# Save it under the form of a json file\n",
    "json.dump(history_dict, open(os.path.join(history_path,'history_Standard_best_Bi_LSTM_Bak_three_min_max_monthly.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7cb9c-8b19-4dea-871e-02f332e28a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading the previous training history\n",
    "history_path = histories_folder_path\n",
    "\n",
    "Bi_LSTM_history = \"history_Standard_best_Bi_LSTM_Bak_three_min_max_monthly.json\"\n",
    "history_dict_Bi_LSTM = json.load(open(os.path.join(history_path,Bi_LSTM_history), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58767d49-ce92-4dea-bdc1-bfbefd0098f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method for saving the saved_data object which includes all of the well data + the computed losses for train, val, and test sets for each phase (oil, gas, water).\n",
    "# Allows comparing models in the future (saves all of the required results)\n",
    "\n",
    "# Prepare to save to the \"All_Results\" folder\n",
    "folder_name = \"All_Results\"\n",
    "All_Results_folder_path = os.path.join(script_dir, folder_name)\n",
    "\n",
    "# Create the \"All_Results\" folder if it does not already exist\n",
    "os.makedirs(All_Results_folder_path, exist_ok=True)\n",
    "\n",
    "print(f\"Folder created at: {All_Results_folder_path}\")\n",
    "\n",
    "save_results_path = All_Results_folder_path\n",
    "\n",
    "with open(os.path.join(save_results_path,'Standard_best_Bi_LSTM_min_max_monthly.pickle'), 'wb') as f:\n",
    "    pickle.dump(saved_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66b55f-1109-4a0b-a56b-a036327c9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to display the training history\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "#plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# Currently available choices in the history json file (depends on how the model was trained): \"loss\", \"val_loss\", \"mae\", \"val_mae\", \"mape\", \"val_mape\" \n",
    "# In this case, only loss (MSE = mean squared error) is shown.\n",
    "plt.plot(history_dict_Bi_LSTM['loss'], lw = 6, color = 'green', label = 'Bi-LSTM Train')\n",
    "plt.plot(history_dict_Bi_LSTM['val_loss'], lw = 2, marker = '^', markevery=1, ms = 10, linestyle ='dotted', color = 'red', label = 'Bi-LSTM Val')\n",
    "\n",
    "plt.xlim(-1,10)\n",
    "plt.title('Model Training', fontsize = 20)\n",
    "plt.ylabel('MSE', fontsize = 20)\n",
    "plt.xlabel('Epochs', fontsize = 20)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.legend(loc='upper right', fontsize = 15)\n",
    "#plt.show()\n",
    "plt.savefig('Min_max_monthly_training_history.png', dpi=300, bbox_inches = 'tight') # saves directly to where the scrip is located. The save path can be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd0a733-b70f-4fbb-af0a-b19f0fe63819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to load all the preiously saved results\n",
    "\n",
    "save_results_path = All_Results_folder_path\n",
    "\n",
    "# possible_selections for \"error_type\" = ['train_error', 'val_error', 'test_error']\n",
    "# possible_selections for \"error\" = ['mse','rmse','mae','mape','nmse','nrmse','nmape','nmae','wmape']\n",
    "# possible_selections for \"phase\" = ['Monthly Oil', 'Monthly Gas', 'Monthly Water']\n",
    "# other possible selections = depends on the available keys (please run the next cell and check the other possibilities)\n",
    "\n",
    "\n",
    "file = open(os.path.join(save_results_path,'Standard_best_Bi_LSTM_min_max_monthly.pickle'),'rb')\n",
    "Standard_best_Bi_LSTM_results = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "error_type = 'val_error'\n",
    "error = 'mse' # all the error types given in the \n",
    "phase = 'Monthly Oil'\n",
    "\n",
    "# Test it\n",
    "Standard_best_Bi_LSTM_results[error_type].loc[Standard_best_Bi_LSTM_results[error_type]['phase'] == phase][error].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa4e65-c427-4038-9518-7b74c81d7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing all the possible keys\n",
    "Standard_best_Bi_LSTM_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c9095-4142-4675-a90a-a8b6abeca794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the saved \"train_results\" contents \n",
    "Standard_best_Bi_LSTM_results['train_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98314ed9-4b44-4816-bebc-99004fc04d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a model\n",
    "\n",
    "# Prepare to save to the \"All_Results\" folder\n",
    "folder_name = \"Models\"\n",
    "Models_folder_path = os.path.join(script_dir, folder_name)\n",
    "\n",
    "# Create the \"All_Results\" folder if it does not already exist\n",
    "os.makedirs(Models_folder_path, exist_ok=True)\n",
    "\n",
    "print(f\"Folder created at: {Models_folder_path}\")\n",
    "\n",
    "save_path = r'C:\\Users\\mrkoc\\Desktop\\RNN_Results\\Models'\n",
    "Standard_best_Bi_LSTM.save(os.path.join(save_path,'Standard_best_Bi_LSTM_monthly.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efead749-056e-4f6c-b86d-9df73f489a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model\n",
    "Loaded_Bi_LSTM = tf.keras.models.load_model(os.path.join(save_path,'Standard_best_Bi_LSTM_monthly.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbc6e9-d9ae-4240-8625-d39fe1460604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the loaded model with the available data\n",
    "Loaded_Bi_LSTM.evaluate(w2_train)\n",
    "Loaded_Bi_LSTM.evaluate(w2_val)\n",
    "Loaded_Bi_LSTM.evaluate(w2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b816cf-056c-4cf3-aab9-85c14490b681",
   "metadata": {},
   "source": [
    "# Additional Examples\n",
    "- Additional Examples: (Many-to-One) + LSTM, GRU, Bi-GRU, ANN, Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251a77b-eaf3-439d-a003-e4e3d5fefb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard RNN (many-to-one) \n",
    "# To see the explanation on how to train these models using the create_model function, check the training for Bi_GRU at the very bottom of this notebook.\n",
    "\n",
    "# w2_train_one = w2_one.train\n",
    "# w2_val_one = w2_one.val\n",
    "# w2_test_one = w2_one.test\n",
    "\n",
    "# If desired, you can modify the functions in the \"utils\" notebook to create a one-to-one or one-to-many model although for production forecasting, it was observed that many-to-many performs brtter (examine how the examples above were created for more insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8a559-9fa9-4eef-8611-7bc72f0d0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If desired to create a linear model, you can change the model_type = 'LR'. This still runs an ANN but, a single layer with a linear activation function (Not recommended for production forecasting).\n",
    "\n",
    "# standard_ann = create_model(final_layer_return_seq = True, loss = 'mse', metrics = ['mae','mape'], layers = 2, dropout_final_layer = False, dropout_value = 0.07490910432625673, units = [144,256], Bi_directional = False, recurrent_dropout = 'zeros', model_type = 'Dense', i = i, optimizer = optimizer)\n",
    "# standard_ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c29a4-046e-4461-92b3-70f750feee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_standard_ann = standard_ann.fit(w2_train, epochs=10, validation_data=w2_val, verbose=2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592ba93-ccfa-4a1f-a1b0-cf376adbdabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard_LSTM = create_model(final_layer_return_seq = True, loss = 'mse', metrics = ['mae','mape'], layers = 2, dropout_final_layer = False, dropout_value = 0.07490910432625673, units = [144,256], Bi_directional = False, recurrent_dropout = 'zeros', model_type = 'LSTM', i = i, optimizer = optimizer) \n",
    "# standard_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fda81-3771-4dcd-b403-e6469dd40932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_standard_LSTM = standard_LSTM.fit(w2_train, epochs=10, validation_data=w2_val, verbose=2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bc49f-5ce7-420b-aa9f-e3c98ceb23fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard_GRU = create_model(final_layer_return_seq = True, loss = 'mse', metrics = ['mae','mape'], layers = 2, dropout_final_layer = False, dropout_value = 0.07490910432625673, units = [144,256], Bi_directional = False, recurrent_dropout = 'zeros', model_type = 'GRU', i = i, optimizer = optimizer) \n",
    "# standard_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452a0ef-4663-4d74-b480-262695a6a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_standard_GRU = standard_GRU.fit(w2_train, epochs=10, validation_data=w2_val, verbose=2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dfd7b0-717d-4ae3-aa39-abee1214c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Bi-directional models -> units = [forward units, backward units] (repeat for each layer)\n",
    "    # units format = when layers = 2 --> units = [[244,250],[132,245]]\n",
    "    # In the example below, since layers = 2, there are 2 units moving forward and backward --> units = [[244,250],[132,245]]. \n",
    "    # So for layer#1 --> units --> [244,250] --> [forward units, backward units] and the next one ([132,245]) is the same for layer#2\n",
    "# This example is for many-to-many models (check above on how to create many-to-one models using the window generator)\n",
    "# For many-to-one models, the final_layer_return_seq = False\n",
    "\n",
    "# standard_Bi_GRU = create_model(final_layer_return_seq = True, loss = 'mse', metrics = ['mae','mape'], layers = 2, dropout_final_layer = False, dropout_value = 0.07490910432625673, units = [[244,250],[132,245]], Bi_directional = True, recurrent_dropout = 'zeros', model_type = 'GRU', i = i, optimizer = optimizer)\n",
    "# standard_Bi_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9463c-e050-4c47-9528-8aa8dd2c1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_standard_Bi_GRU = standard_Bi_GRU.fit(w2_train, epochs=10, validation_data=w2_val, verbose=2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265077ab-6203-4972-a80a-dc885ee7fc91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu]",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
